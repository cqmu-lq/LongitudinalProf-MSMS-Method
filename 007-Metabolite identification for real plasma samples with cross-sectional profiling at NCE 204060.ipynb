{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2babd0-6169-4fbb-8fc3-1569c5b05d43",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Calculate the similarity of 204060 mzML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b87f8b-a9b2-40fc-b77a-1df1b6519ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import mzbatch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import importlib as imp\n",
    "imp.reload(mzbatch)\n",
    "import subprocess\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8df52f-7613-4fe3-9011-18d9df4b4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = f'../../Fulaoshi/230821_mzML/'\n",
    "analysis_batch = \"BloodYin240307\"\n",
    "rawfile_batch = \"QCidentify_1\"\n",
    "ev13_list = [1,10,15,20,25,30,35,40,50,60,70,80,100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091612ed-dfc2-4ec0-bd14-80f51e8af829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"load reference\"\"\"\n",
    "ref_all_df = pd.read_csv(\"../../Fulaoshi/230821_mzML/ref_all_增加evlist和nums.csv\",index_col=0)\n",
    "ref_all_df['batch_sampleid'] = ref_all_df['batch']+'/'+ref_all_df['sampleid']\n",
    "ref_all_df['bscp']=ref_all_df['batch']+'+'+ref_all_df['sampleid'].astype(str)+'+'+ref_all_df['CAS No.']+'+'+ref_all_df['pos_neg']\n",
    "ref_all_df[\"filepath\"] = \"../../Fulaoshi/230821_mzML_res/rerun240410/\"+ref_all_df[\"batch\"]+\"/NCE_compound_filter_1/\"+ref_all_df[\"sampleid\"].astype(str)+\"/\"+ref_all_df[\"CAS No.\"]+\"_NCE204060_\"+ref_all_df[\"pos_neg\"]\n",
    "print(ref_all_df.shape)\n",
    "ref_all_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beacbbd8-e62e-45ec-8ef7-fad2182c71d9",
   "metadata": {},
   "source": [
    "### Establishing Basic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb12b5b-c649-4c34-8fdb-43559a14f522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Establishing four mz_list\n",
    "Amide_pos_mzlist = ref_all_df[(ref_all_df[\"sepuzhu\"] == \"Amide\") & (ref_all_df[\"pos_neg\"] == \"pos\")][\"m/z\"].tolist()\n",
    "Amide_pos_mzlist.sort()\n",
    "Amide_neg_mzlist = ref_all_df[(ref_all_df[\"sepuzhu\"] == \"Amide\") & (ref_all_df[\"pos_neg\"] == \"neg\")][\"m/z\"].tolist()\n",
    "Amide_neg_mzlist.sort()\n",
    "C18_pos_mzlist = ref_all_df[(ref_all_df[\"sepuzhu\"] == \"C18\") & (ref_all_df[\"pos_neg\"] == \"pos\")][\"m/z\"].tolist()\n",
    "C18_pos_mzlist.sort()\n",
    "C18_neg_mzlist = ref_all_df[(ref_all_df[\"sepuzhu\"] == \"C18\") & (ref_all_df[\"pos_neg\"] == \"neg\")][\"m/z\"].tolist()\n",
    "C18_neg_mzlist.sort()\n",
    "\n",
    "# Establishing upper and lower limits for the four mz_lists\n",
    "Ap_mzrange_list = [[i, mzbatch.get_mz_range(i, diff=15)] for i in Amide_pos_mzlist]\n",
    "An_mzrange_list = [[i, mzbatch.get_mz_range(i, diff=15)] for i in Amide_neg_mzlist]\n",
    "Cp_mzrange_list = [[i, mzbatch.get_mz_range(i, diff=15)] for i in C18_pos_mzlist]\n",
    "Cn_mzrange_list = [[i, mzbatch.get_mz_range(i, diff=15)] for i in C18_neg_mzlist]\n",
    "\n",
    "mzrange_dict = {\"Amide_pos\": Ap_mzrange_list, \"Amide_neg\": An_mzrange_list, \n",
    "                \"C18_pos\": Cp_mzrange_list, \"C18_neg\": Cn_mzrange_list}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a870438b-2e1b-4a52-9777-6e2673efb0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "l1_list = [\"Amide\",\"C18\"][0:]\n",
    "l2_list = [\"pos\",\"neg\"][0:]\n",
    "folder_combina_list = list(itertools.product(l1_list, l2_list))\n",
    "len(folder_combina_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f446af29-9df9-405d-8040-37dcc507368e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Build the Area_cols_dict\"\"\"\n",
    "Area_cols_dict={}\n",
    "for temp_sepuzhu,temp_pos_neg in [['Amide', 'pos'],['Amide', 'neg'],['C18', 'pos'],['C18', 'neg']]:\n",
    "    MS_DIAL_list = os.listdir(f\"../../Fulaoshi/230821_mzML/{analysis_batch}_{temp_sepuzhu}_{temp_pos_neg}/MS-DIAL\")\n",
    "    Area13_filename_list = [i for i in MS_DIAL_list if i.startswith(\"Area\")]\n",
    "    Area13_df = pd.read_csv(f\"../../Fulaoshi/230821_mzML/{analysis_batch}_{temp_sepuzhu}_{temp_pos_neg}/MS-DIAL/{Area13_filename_list[0]}\", sep=\"\\t\",index_col=0)\n",
    "    if analysis_batch==\"BloodNaoLiu240807\":\n",
    "        Area_cols_list = [i for i in Area13_df.columns if ((i.endswith(f\"-{temp_pos_neg}\")&(i.count('-'))))]\n",
    "    else:\n",
    "        Area_cols_list = [i for i in Area13_df.columns if ((i.strip().endswith(f\"-{temp_pos_neg}\")&(i.count('-')==2)&(i.count('_')==0)))]\n",
    "    Area_cols_dict[f\"{temp_sepuzhu}_{temp_pos_neg}\"] = Area_cols_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c55a0-0362-4c01-87a6-b00dcb46799a",
   "metadata": {},
   "source": [
    "### Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5d5ab-38cd-4cce-be78-c0a4244ff599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw大小： (4691, 9)\n",
      "raw大小： (7073, 9)\n",
      "raw大小： (8249, 9)\n",
      "raw大小： (4681, 9)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"First filter the mz of 4 204060 mzML with the 4000 standard library\"\"\"\n",
    "for folder_sepuzhu, folder_pos_neg in folder_combina_list[0:]:\n",
    "    mzrange_list = mzrange_dict[f\"{folder_sepuzhu}_{folder_pos_neg}\"]\n",
    "    analysis_path = f\"{analysis_batch}_{folder_sepuzhu}_{folder_pos_neg}\"\n",
    "    \n",
    "    mzML_path = f\"{root_path}/{analysis_path}/mzML/{rawfile_batch}-NCE204060-{folder_pos_neg}.mzML\"\n",
    "    pkl_path = f\"{root_path}/{analysis_path}/pkl/{rawfile_batch}-NCE204060-{folder_pos_neg}.pkl\"\n",
    "    pkl_filter_folderpath = f\"{root_path}/{analysis_path}/pkl_filter/\"\n",
    "    pkl_filter_path = f\"{root_path}/{analysis_path}/pkl_filter/{rawfile_batch}-NCE204060-{folder_pos_neg}.pkl\"\n",
    "    \n",
    "    raw_list = mzbatch.get_TIC_from_File(mzML_path, pkl_path)\n",
    "    raw_df = pd.DataFrame(raw_list)\n",
    "    raw_ms2_df = raw_df[raw_df[\"MSlevel\"] == 2]\n",
    "    \n",
    "    valid_index_list = []  # Result indices\n",
    "    for theo_mz, (mz_low, mz_up) in mzrange_list:\n",
    "        temp_df = raw_ms2_df[(raw_ms2_df['pecursor'] >= mz_low) & (raw_ms2_df['pecursor'] <= mz_up)]\n",
    "        if temp_df.shape[0] > 0:\n",
    "            valid_index_list.extend(temp_df.index.tolist())\n",
    "        # break\n",
    "    valid_index_list = list(set(valid_index_list))\n",
    "    valid_index_list.sort()\n",
    "    \n",
    "    if not os.path.exists(pkl_filter_folderpath):\n",
    "        os.makedirs(pkl_filter_folderpath)\n",
    "        while os.path.exists(pkl_filter_folderpath):\n",
    "            break\n",
    "    raw_ms2_df.loc[valid_index_list, :].to_pickle(pkl_filter_path)\n",
    "\n",
    "    print(\"raw size:\", raw_ms2_df.loc[valid_index_list, :].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ef351-f5cd-432a-9b1d-0f3588bf0b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sepuzhu, pos_neg in folder_combina_list[0:]: \n",
    "    analysis_path = f\"{analysis_batch}_{sepuzhu}_{pos_neg}\"\n",
    "    pkl_filter_folderpath = f\"{root_path}/{analysis_path}/pkl_filter/\"\n",
    "\n",
    "    qc_filename = f'../../Fulaoshi/230821_mzML/BloodYin240307_{sepuzhu}_{pos_neg}//MS-DIAL/QCidentify_1-NCE204060-{pos_neg}.txt'\n",
    "    mzrange_list = mzrange_dict[f\"{sepuzhu}_{pos_neg}\"]\n",
    "    \n",
    "    QC246_df = pd.read_csv(qc_filename, index_col=0, sep=\"\\t\")\n",
    "    QC246_df = QC246_df.loc[:, [\"RT left(min)\", \"RT right (min)\", \"Precursor m/z\", \"Area\"]]\n",
    "    QC246_df[\"RT left(s)\"] = QC246_df[\"RT left(min)\"] * 60\n",
    "    QC246_df[\"RT right(s)\"] = QC246_df[\"RT right (min)\"] * 60\n",
    "    \n",
    "    # Filter QC246 based on mz\n",
    "    QC_valid_index_list = []  # Result indices\n",
    "    theo_mz_list = []\n",
    "    for theo_mz, (mz_low, mz_up) in mzrange_list[0:]:\n",
    "        temp_QC246_df = QC246_df[(QC246_df['Precursor m/z'] >= mz_low) & (QC246_df['Precursor m/z'] <= mz_up)]\n",
    "        if temp_QC246_df.shape[0] > 0:\n",
    "            QC_valid_index_list.extend(temp_QC246_df.index.tolist())\n",
    "            theo_mz_list.extend([theo_mz] * temp_QC246_df.shape[0])\n",
    "    \n",
    "    QC246_filter_df = QC246_df.loc[QC_valid_index_list, :].copy(deep=True)\n",
    "    QC246_filter_df[\"theo_mz\"] = theo_mz_list\n",
    "    QC246_filter_df.drop_duplicates(subset=['Precursor m/z', 'RT left(s)', 'RT right(s)', 'theo_mz'], inplace=True)\n",
    "    QC246_filter_df.sort_values(by=\"theo_mz\", inplace=True)\n",
    "    QC246_filter_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Output to file\n",
    "    if not os.path.exists(pkl_filter_folderpath):\n",
    "        os.makedirs(pkl_filter_folderpath)\n",
    "        while os.path.exists(pkl_filter_folderpath):\n",
    "            break\n",
    "    QC246_filter_df.to_pickle(f\"{pkl_filter_folderpath}/QC246_filter_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8555d4e-e773-48dd-aa70-96eeb6fed4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Based on the combination of 13 QCS, the similarity is calculated for 204060 where mz is within 15ppm and rt is within the range\"\"\"\n",
    "res_df_dict = {}\n",
    "for sepuzhu, pos_neg in folder_combina_list[0:]:\n",
    "    analysis_path = f\"{analysis_batch}_{sepuzhu}_{pos_neg}\"\n",
    "    pkl_filter_folderpath = f\"{root_path}/{analysis_path}/pkl_filter/\"\n",
    "    pkl_filter_path = f\"{root_path}/{analysis_path}/pkl_filter/{rawfile_batch}-NCE204060-{pos_neg}.pkl\"\n",
    "    pkl_path = f\"{root_path}/{analysis_path}/pkl/{rawfile_batch}-NCE204060-{pos_neg}.pkl\"\n",
    "    \n",
    "    # Get MS1 data\n",
    "    raw_df = pd.DataFrame(pd.read_pickle(pkl_path))\n",
    "    raw_ms1_df = raw_df[raw_df[\"MSlevel\"] == 1]\n",
    "    \n",
    "    # Read QC35 and raw_filter_ms2_df\n",
    "    QC35_filter_df = pd.read_pickle(f\"{pkl_filter_folderpath}/con_QC_filter_df.pkl\")\n",
    "    raw_filter_ms2_df = pd.read_pickle(pkl_filter_path)\n",
    "    \n",
    "    # Construct DataFrame to store results\n",
    "    res_cols_list = [\"theo_mz\", \"ref_ev\", \"ref_mz\", \"ref_rt_left\", \"ref_rt_right\", \"Area\", \"ms2_ev\", \"ms2_index\", \"ms2_mz\", \"ms2_rt\", \"ms1_intensity\"]\n",
    "    \n",
    "    res_df = pd.DataFrame(columns=res_cols_list)\n",
    "    ref_ev = 35\n",
    "    n = 0\n",
    "    for QC35_filter_index in QC35_filter_df.index[0:]:  # QC35 is all 1\n",
    "        theo_mz, ref_mz, ref_rt_left, ref_rt_right, Area = QC35_filter_df.loc[QC35_filter_index, [\"theo_mz\", 'Precursor m/z', \"RT left(s)\", \"RT right(s)\", \"Area\"]]\n",
    "        ref_mz_low, ref_mz_up = mzbatch.get_mz_range(ref_mz, diff=15)\n",
    "\n",
    "        ms2_ev = \"204060\"\n",
    "        ms2_temp_df = raw_filter_ms2_df[((raw_filter_ms2_df['pecursor'] >= ref_mz_low) & (raw_filter_ms2_df['pecursor'] <= ref_mz_up)) \n",
    "                                          & ((raw_filter_ms2_df['RT'] >= ref_rt_left) & (raw_filter_ms2_df['RT'] <= ref_rt_right))].copy(deep=True)\n",
    "        if ms2_temp_df.shape[0] > 0:\n",
    "            for ms2_index in ms2_temp_df.index:\n",
    "                ms2_mz, ms2_rt, ms2_peaks = ms2_temp_df.loc[ms2_index, [\"pecursor\", \"RT\", \"peaks\"]]\n",
    "                ms2_mz_low, ms2_mz_up = mzbatch.get_mz_range(ms2_mz)\n",
    "                # Calculate MS1 intensity\n",
    "                ms1_df = pd.DataFrame(raw_ms1_df[raw_ms1_df[\"RT\"] < ms2_rt].iloc[-1, -2], columns=[\"Mass\", \"Intensity\"])\n",
    "                ms1_intensity_filter_df = ms1_df[(ms1_df['Mass'] >= ms2_mz_low) & (ms1_df['Mass'] <= ms2_mz_up)]\n",
    "                if ms1_intensity_filter_df.shape[0] > 0:\n",
    "                    ms1_intensity = ms1_intensity_filter_df[\"Intensity\"].max()\n",
    "                else:\n",
    "                    ms1_intensity = -1\n",
    "                nce_compound_204060_folder = os.path.dirname(f'../../Fulaoshi/230821_mzML_res/{analysis_path}/NCE_compound_204060/{ms2_index}.csv')\n",
    "                if not os.path.exists(nce_compound_204060_folder):\n",
    "                    os.makedirs(nce_compound_204060_folder)\n",
    "                    while os.path.exists(nce_compound_204060_folder):\n",
    "                        break\n",
    "                pd.DataFrame(ms2_temp_df.loc[ms2_index, \"peaks\"], columns=[\"Mass\", \"Intensity\"]).to_csv(f'../../Fulaoshi/230821_mzML_res/{analysis_path}/NCE_compound_204060/{ms2_index}.csv')  # Output MS2 data to file\n",
    "                res_df.loc[n] = [theo_mz, ref_ev, ref_mz, ref_rt_left, ref_rt_right, Area, ms2_ev, ms2_index, ms2_mz, ms2_rt, ms1_intensity]\n",
    "                n += 1\n",
    "            # break\n",
    "    # Discard -1, only keep the MS1 intensity maximum spectrum\n",
    "    res_nofu1_df = res_df[res_df[\"ms1_intensity\"] != -1]\n",
    "    max_ms1_indexes = res_nofu1_df.groupby(by=['theo_mz', 'ref_rt_left', 'ref_rt_right', 'ms2_ev'])['ms1_intensity'].idxmax()\n",
    "    res_maxms1_df = res_nofu1_df.loc[max_ms1_indexes, :]\n",
    "    \n",
    "    res_df_dict[f\"{sepuzhu}+{pos_neg}\"] = res_maxms1_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82d4ba8e-0a4e-4d0e-8ef1-6d211f6a7286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fangda(x):\n",
    "    if x=='-1' or x=='[[]]' or x==-1:\n",
    "        return [[-1]*Area_lens]\n",
    "    else:\n",
    "        return x\n",
    "Area_lens = len(Area_cols_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d087ce4-a72f-43e6-908b-fee9d3c18ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"res_df adds Area13 columns\"\"\"\n",
    "for sepuzhu, pos_neg in folder_combina_list[0:]:\n",
    "    res_groupby_df = res_df_dict[f\"{sepuzhu}+{pos_neg}\"]\n",
    "    MS_DIAL_list = os.listdir(f\"../../Fulaoshi/230821_mzML/{analysis_batch}_{sepuzhu}_{pos_neg}/MS-DIAL\")\n",
    "    Area13_filename_list = [i for i in MS_DIAL_list if i.startswith(\"Area\")]\n",
    "    Area13_df = pd.read_csv(f\"../../Fulaoshi/230821_mzML/{analysis_batch}_{sepuzhu}_{pos_neg}/MS-DIAL/{Area13_filename_list[0]}\", sep=\"\\t\",index_col=0)\n",
    "    Area13_df[\"Average Rt(s)\"] = Area13_df[\"Average Rt(min)\"]*60\n",
    "    Area_cols_list = Area_cols_dict[f\"{sepuzhu}_{pos_neg}\"]\n",
    "    Area13_3list = []\n",
    "    for res_groupby_index in res_groupby_df.index[0:]:\n",
    "        res_groupby_mz, res_groupby_rt_low, res_groupby_rt_up = res_groupby_df.loc[res_groupby_index,['ref_mz', 'ref_rt_left', 'ref_rt_right']] #240915修改为theo_mz\n",
    "        res_groupby_mz_low, res_groupby_mz_up = mzbatch.get_mz_range(res_groupby_mz)\n",
    "\n",
    "        temp_Area13_df = Area13_df[((Area13_df['Average Mz'] >= res_groupby_mz_low) & (Area13_df['Average Mz'] <= res_groupby_mz_up))\n",
    "                  & ((Area13_df['Average Rt(s)'] >= res_groupby_rt_low) & (Area13_df['Average Rt(s)'] <= res_groupby_rt_up))]\n",
    "        if temp_Area13_df.shape[0]==1:\n",
    "            Area13_3list.append(temp_Area13_df.loc[:,Area_cols_list].values.tolist())\n",
    "        elif temp_Area13_df.shape[0]>1:\n",
    "            Area13_3list.append(temp_Area13_df.loc[:,Area_cols_list].values.tolist())\n",
    "        else:\n",
    "            Area13_3list.append(-1)\n",
    "    res_groupby_df[\"Area13_2list\"] = Area13_3list\n",
    "    # handle\n",
    "    res_groupby_df[\"Area13_2list\"] = res_groupby_df[\"Area13_2list\"].apply(lambda x:fangda(x))\n",
    "    res_groupby_df[\"Area13_2list\"] = res_groupby_df[\"Area13_2list\"].apply(lambda x:eval(str(x)))\n",
    "    res_groupby_df = res_groupby_df.explode(\"Area13_2list\") \n",
    "    res_groupby_df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    res_df_dict[f\"{sepuzhu}+{pos_neg}\"] = res_groupby_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5ff04-f5f0-45ab-8781-85d1912451a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字典已保存到 ../../Fulaoshi/230821_mzML/res_df_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(f\"../../Fulaoshi/230821_mzML/res_df_dict.pkl\", 'wb') as f:\n",
    "    pickle.dump(res_df_dict, f)\n",
    "\n",
    "print(\"The dictionary has been saved to ../../Fulaoshi/230821_mzML/res_df_dict.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9020813-9dd9-4dfa-b956-01e35a762c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dictionary from the .pkl file\n",
    "with open('../../Fulaoshi/230821_mzML/res_df_dict.pkl', 'rb') as f:\n",
    "    res_df_dict = pickle.load(f)\n",
    "\n",
    "print(\"The dictionary loaded from output.pkl is:\", res_df_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba1c5888-a4d7-4177-a2ca-1f8d575454a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " [('Amide', 'pos', 'cosine'),\n",
       "  ('Amide', 'pos', 'jaccard'),\n",
       "  ('Amide', 'pos', 'entropy'),\n",
       "  ('Amide', 'neg', 'cosine'),\n",
       "  ('Amide', 'neg', 'jaccard')])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "l1_list = [\"Amide\",\"C18\"][0:]\n",
    "l2_list = [\"pos\",\"neg\"][0:]\n",
    "l3_list = [\"cosine\",\"jaccard\",\"entropy\"][0:]\n",
    "combine3_list = list(itertools.product(l1_list, l2_list, l3_list))\n",
    "len(combine3_list),combine3_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c2bf43b-8540-4e3a-89e3-f8fd260f0fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cal_fragment(fragment_mzrange_list, b2_mzlist):\n",
    "    # Convert lists to NumPy arrays\n",
    "    b2_mzarray = np.array(b2_mzlist)\n",
    "    fragment_mzrange_array = np.array(fragment_mzrange_list) * 1e6\n",
    "    # Separate the lower and upper bounds of the ranges\n",
    "    ilow = fragment_mzrange_array[:, 0]\n",
    "    iup = fragment_mzrange_array[:, 1]\n",
    "    # Use boolean indexing to find elements that meet the conditions\n",
    "    mask = (b2_mzarray[:, np.newaxis] >= ilow) & (b2_mzarray[:, np.newaxis] <= iup)\n",
    "    # Find all m/z values that satisfy the conditions\n",
    "    matched_indices = np.where(mask.any(axis=1))[0]\n",
    "    fragment_mzlist = b2_mzarray[matched_indices]\n",
    "    return fragment_mzlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "794e7573-d7a6-4144-861d-bb62263253f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take ref_all as the standard diagram b1, and find the corresponding b2 from ref_df\n",
    "for sepuzhu, pos_neg, sim_method in combine3_list[0:]:\n",
    "    n = 0\n",
    "    Area_cols_list = Area_cols_dict[f\"{sepuzhu}_{pos_neg}\"]\n",
    "    hengxiang204060_df = pd.DataFrame(columns=[\"sepuzhu\", \"pos_neg\", \"bscp1\", \"b1_name\", \"b1_adduct\", \"b2_index\", \"b2_mz\", \"b2_rt\", \"pos_sim\"] + Area_cols_list)\n",
    "    analysis_path = f\"{analysis_batch}_{sepuzhu}_{pos_neg}\"\n",
    "    pattern_ref_all_df = ref_all_df[(ref_all_df[\"sepuzhu\"] == sepuzhu) & (ref_all_df[\"pos_neg\"] == pos_neg)]\n",
    "    res_df = res_df_dict[f\"{sepuzhu}+{pos_neg}\"]\n",
    "    for i in res_df.index[0:]:\n",
    "        ref_mz, ref_rt_left, ref_rt_right, ms2_ev, ms2_index, ms2_mz, ms2_rt, Area13_2list = res_df.loc[i, [\"ref_mz\", \"ref_rt_left\", \"ref_rt_right\", \"ms2_ev\", \"ms2_index\", \"ms2_mz\", \"ms2_rt\", \"Area13_2list\"]]\n",
    "        # Area13_2list = eval(Area13_2list)\n",
    "        ms2_mz_low, ms2_mz_up = mzbatch.get_mz_range(ms2_mz, diff=15)\n",
    "        temp_pattern_ref_all_df = pattern_ref_all_df[(pattern_ref_all_df['m/z'] >= ms2_mz_low) & (pattern_ref_all_df['m/z'] <= ms2_mz_up)]\n",
    "        # & (pattern_ref_all_df['RT time'] >= ref_rt_left) & (pattern_ref_all_df['RT time'] <= ref_rt_right)]\n",
    "        if temp_pattern_ref_all_df.shape[0] > 0:\n",
    "            for j in temp_pattern_ref_all_df.index[0:]:\n",
    "                bscp1, b1_name, b1_adduct, b1_mz, temp_filepath = temp_pattern_ref_all_df.loc[j, [\"bscp\", \"Product Name\", \"Adduct\", \"m/z\", \"filepath\"]]\n",
    "                batch1, sampleid1, cas1, pos_neg1 = bscp1.split(\"+\")\n",
    "                if ((not os.path.exists(temp_filepath)) or (os.listdir(temp_filepath) == [])):\n",
    "                    continue\n",
    "                temp_filename = os.listdir(temp_filepath)[0]\n",
    "                b1_df = mzbatch.read_data(f\"{temp_filepath}/{temp_filename}\", b1_mz, rate=100)\n",
    "                # b2_df = mzbatch.read_data(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/NCE_compound_204060/{ms2_index}.csv\", ms2_mz, rate=100) #240915 modification, add b2 fragment filtering\n",
    "                \n",
    "                # Filter b2 fragments: first find b1 fragments\n",
    "                filter_fragment_path = f\"../../Fulaoshi/230821_mzML_res/rerun240410/{batch1}/NCE_filter_fragment/{bscp1}.csv\"\n",
    "                if not os.path.exists(filter_fragment_path):\n",
    "                    # print(f\"{bscp1} has no fragments\")\n",
    "                    continue\n",
    "                fragment_list = eval(pd.read_csv(filter_fragment_path, index_col=0)[\"filter_fragment\"].tolist()[0])\n",
    "                fragment_mzrange_list = mzbatch.get_mz_range_matrix(fragment_list, diff=15)\n",
    "                # print(fragment_mzrange_list)\n",
    "                \n",
    "                # Read data, first read b2, filter b2 fragments and skip to the next loop if none are found\n",
    "                # b2_df = pd.read_csv(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/NCE_compound_204060/{ms2_index}.csv\", index_col=0)\n",
    "                b2_df = mzbatch.read_data(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/NCE_compound_204060/{ms2_index}.csv\", ms2_mz, rate=1000000) #240915 modification, add b2 fragment filtering\n",
    "                # Filter b2 fragments\n",
    "                b2_mzlist = b2_df.index.tolist()\n",
    "                # print(len(b2_mzlist))\n",
    "                fragment_res_list = cal_fragment(fragment_mzrange_list, b2_mzlist)\n",
    "                # Skip similarity calculation with b1 if no fragments are found\n",
    "                if len(fragment_res_list) == 0:\n",
    "                    # print(f\"Unknown spectrum {ms2_index} has no matching fragments, {len(fragment_res_list)}\")\n",
    "                    continue\n",
    "                # print(f\"===={bscp1} and unknown spectrum alignment {temp_res_index} have matching fragments, {len(fragment_res_list)}\")\n",
    "\n",
    "                # Filter b2 based on fragment results\n",
    "                b2_df = b2_df.loc[fragment_res_list, :]\n",
    "                b2_df[\"new_mass\"] = np.around(np.array(fragment_res_list) / 1e4).astype(int)\n",
    "                b2_df = b2_df.set_index(\"new_mass\")\n",
    "                b2_df = b2_df.groupby(b2_df.index).max()\n",
    "                b2_df = mzbatch.to_relative_abundance(b2_df)\n",
    "                b2_df = b2_df.mask(b2_df < 0.02, 0)\n",
    "                b2_df = b2_df[(b2_df != 0).any(axis=1)]\n",
    "                \n",
    "                # Calculate similarity\n",
    "                temp_b12_df = pd.concat([b1_df, b2_df], axis=1)\n",
    "                temp_b12_df.columns = [-1, 0]\n",
    "                temp_b12_df = temp_b12_df.fillna(0)\n",
    "                temp_b12_df = mzbatch.to_relative_abundance(temp_b12_df)  #240805 convert to relative abundance!!, very important\n",
    "                temp_b12_df = temp_b12_df.fillna(0)\n",
    "                if sim_method == \"cosine\":\n",
    "                    pos_sim_list = np.square(mzbatch.cal_pos_sim(temp_b12_df, sim_method=sim_method)).tolist()\n",
    "                else:\n",
    "                    pos_sim_list = mzbatch.cal_pos_sim(temp_b12_df, sim_method=sim_method)\n",
    "                if Area13_2list == -1:\n",
    "                    hengxiang204060_df.loc[n] = [sepuzhu, pos_neg, bscp1, b1_name, b1_adduct, ms2_index, ms2_mz, ms2_rt, pos_sim_list[0]] + [Area13_2list] * len(Area_cols_list)\n",
    "                else:\n",
    "                    hengxiang204060_df.loc[n] = [sepuzhu, pos_neg, bscp1, b1_name, b1_adduct, ms2_index, ms2_mz, ms2_rt, pos_sim_list[0]] + Area13_2list\n",
    "                n += 1\n",
    "    hengxiang204060_df.to_csv(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/hengxiang204060_{sim_method}_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467d8076-203d-485a-91bc-4cb40b14865a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "for sepuzhu, pos_neg, sim_method in combine3_list[0:]:\n",
    "    analysis_path = f\"{analysis_batch}_{sepuzhu}_{pos_neg}\"\n",
    "    hengxiang204060_df = pd.read_csv(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/hengxiang204060_{sim_method}_df.csv\", index_col=0)\n",
    "    hengxiang204060_nochong_df = hengxiang204060_df.drop_duplicates(subset=hengxiang204060_df.columns.tolist())\n",
    "    hengxiang204060_nochong_df.to_csv(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/deduplicated_hengxiang204060_{sim_method}_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1ef07-cbba-4c50-b4f8-817105be626a",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Statistical unique term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2da9fa95-94c2-4767-bb61-86f8e1e5f7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_intersect(interval1, interval2):\n",
    "    a, b = interval1\n",
    "    c, d = interval2\n",
    "    \n",
    "    if max(a, c) <= min(b, d):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95aa5540-f12c-432a-b216-448432c797e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>sepuzhu</th>\n",
       "      <th>sampleid</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>CAS No.</th>\n",
       "      <th>Formula</th>\n",
       "      <th>M.Wt</th>\n",
       "      <th>pos_neg</th>\n",
       "      <th>refer_RT</th>\n",
       "      <th>m/z</th>\n",
       "      <th>RT time</th>\n",
       "      <th>NL</th>\n",
       "      <th>bscp</th>\n",
       "      <th>Adduct</th>\n",
       "      <th>batch_sampleid</th>\n",
       "      <th>ev_nums</th>\n",
       "      <th>ev_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>873_C18</td>\n",
       "      <td>C18</td>\n",
       "      <td>26386</td>\n",
       "      <td>N6-Methyladenosine</td>\n",
       "      <td>1867-73-8</td>\n",
       "      <td>C11H15N5O4</td>\n",
       "      <td>281.27</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>282.1196</td>\n",
       "      <td>285.0</td>\n",
       "      <td>133000000</td>\n",
       "      <td>873_C18+26386+1867-73-8+pos</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>873_C18/26386</td>\n",
       "      <td>13</td>\n",
       "      <td>[1, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>873_C18</td>\n",
       "      <td>C18</td>\n",
       "      <td>26386</td>\n",
       "      <td>Corticosterone</td>\n",
       "      <td>50-22-6</td>\n",
       "      <td>C21H30O4</td>\n",
       "      <td>346.46</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "      <td>347.2216</td>\n",
       "      <td>874.8</td>\n",
       "      <td>111000000</td>\n",
       "      <td>873_C18+26386+50-22-6+pos</td>\n",
       "      <td>[M+H]+</td>\n",
       "      <td>873_C18/26386</td>\n",
       "      <td>13</td>\n",
       "      <td>[1, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        batch sepuzhu sampleid        Product Name    CAS No.     Formula  \\\n",
       "1104  873_C18     C18    26386  N6-Methyladenosine  1867-73-8  C11H15N5O4   \n",
       "1106  873_C18     C18    26386      Corticosterone    50-22-6    C21H30O4   \n",
       "\n",
       "        M.Wt pos_neg  refer_RT       m/z  RT time         NL  \\\n",
       "1104  281.27     pos         1  282.1196    285.0  133000000   \n",
       "1106  346.46     pos         1  347.2216    874.8  111000000   \n",
       "\n",
       "                             bscp  Adduct batch_sampleid  ev_nums  \\\n",
       "1104  873_C18+26386+1867-73-8+pos  [M+H]+  873_C18/26386       13   \n",
       "1106    873_C18+26386+50-22-6+pos  [M+H]+  873_C18/26386       13   \n",
       "\n",
       "                                                ev_list  \n",
       "1104  [1, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80...  \n",
       "1106  [1, 10, 15, 20, 25, 30, 35, 40, 50, 60, 70, 80...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Reference file for loading statistics\"\"\"\n",
    "static_ref_all_df = pd.read_excel(\"../../Fulaoshi/230821_mzML/ref_all-revise20240920.xlsx\",index_col=0,sheet_name=\"Sheet2\")\n",
    "static_ref_all_df['batch_sampleid'] = static_ref_all_df['batch'].astype(str)+'/'+static_ref_all_df['sampleid'].astype(str)\n",
    "static_ref_all_df['bscp']=static_ref_all_df['batch']+'+'+static_ref_all_df['sampleid'].astype(str)+'+'+static_ref_all_df['CAS No.'].astype(str)+'+'+static_ref_all_df['pos_neg']\n",
    "static_ref_all_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd108b26-0b2b-4c8b-8719-0ef1a78a4afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sepuzhu, pos_neg, sim_method in combine3_list[0:]:\n",
    "    Area_cols_list = Area_cols_dict[f\"{sepuzhu}_{pos_neg}\"]\n",
    "    analysis_path = f\"{analysis_batch}_{sepuzhu}_{pos_neg}\"\n",
    "    hengxiang204060_nochong_df = pd.read_csv(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/deduplicated_hengxiang204060_{sim_method}_df.csv\", index_col=0)\n",
    "    hengxiang204060_nochong_df = hengxiang204060_nochong_df[hengxiang204060_nochong_df[Area_cols_list[0]] != -1]\n",
    "    hengxiang204060_nochong_df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    temp_hengxiang204060_df = hengxiang204060_nochong_df[Area_cols_list]\n",
    "    temp_hengxiang204060_df = temp_hengxiang204060_df.astype(str)\n",
    "    temp_hengxiang204060_df['Area_sum'] = temp_hengxiang204060_df.apply(lambda row: ''.join(row), axis=1)\n",
    "    hengxiang204060_nochong_df[\"Area_sum\"] = temp_hengxiang204060_df['Area_sum']\n",
    "    \n",
    "    res_groupby_df = res_df_dict[f\"{sepuzhu}+{pos_neg}\"]\n",
    "\n",
    "    b1_ref_rt_list, b2_rt_left_list, b2_rt_right_list = [], [], []\n",
    "    for index204060 in hengxiang204060_nochong_df.index[0:]:\n",
    "        static_bscp1, static_b2_index = hengxiang204060_nochong_df.loc[index204060, [\"bscp1\", \"b2_index\"]]\n",
    "\n",
    "        temp_ref_all_df = static_ref_all_df[static_ref_all_df['bscp'] == static_bscp1]\n",
    "        if temp_ref_all_df.shape[0] == 0:\n",
    "            b1_ref_rt_list.append(-100)  # Modified on 240920\n",
    "        else:\n",
    "            b1_ref_rt = temp_ref_all_df.loc[temp_ref_all_df.index[0], \"RT time\"]\n",
    "            b1_ref_rt_list.append(b1_ref_rt)\n",
    "\n",
    "        temp_res_groupby_df = res_groupby_df[res_groupby_df[\"ms2_index\"] == static_b2_index]\n",
    "        temp_b2_rt_df = temp_res_groupby_df.groupby([\"ms2_index\"]).agg(ref_rt_left=('ref_rt_left', \"min\"), ref_rt_right=('ref_rt_right', 'max')).reset_index()\n",
    "        b2_rt_left, b2_rt_right = temp_b2_rt_df.loc[temp_b2_rt_df.index[0], [\"ref_rt_left\", \"ref_rt_right\"]]\n",
    "        b2_rt_left_list.append(b2_rt_left)\n",
    "        b2_rt_right_list.append(b2_rt_right)\n",
    "\n",
    "    hengxiang204060_nochong_df[\"b1_ref_rt\"] = b1_ref_rt_list\n",
    "    hengxiang204060_nochong_df[\"b1_rt_left\"] = hengxiang204060_nochong_df[\"b1_ref_rt\"] - 15\n",
    "    hengxiang204060_nochong_df[\"b1_rt_right\"] = hengxiang204060_nochong_df[\"b1_ref_rt\"] + 15\n",
    "    hengxiang204060_nochong_df[\"b2_rt_left\"] = b2_rt_left_list\n",
    "    hengxiang204060_nochong_df[\"b2_rt_right\"] = b2_rt_right_list\n",
    "    hengxiang204060_nochong_df[\"has_intersect\"] = hengxiang204060_nochong_df.apply(lambda x: is_intersect([x[\"b1_rt_left\"], x[\"b1_rt_right\"]], [x[\"b2_rt_left\"], x[\"b2_rt_right\"]]), axis=1)\n",
    "\n",
    "    hengxiang_colist = list(hengxiang204060_nochong_df.columns)\n",
    "    Area_first_col = \"Area_sum\"\n",
    "    hengxiang204060_nochong_df[\"is_max_sim\"] = 0\n",
    "    max_similarity_indexes = hengxiang204060_nochong_df.groupby(by=[Area_first_col])['pos_sim'].idxmax()\n",
    "    hengxiang204060_nochong_df.loc[max_similarity_indexes, \"is_max_sim\"] = 1\n",
    "    hengxiang204060_nochong_df = hengxiang204060_nochong_df[hengxiang204060_nochong_df[\"b1_ref_rt\"] != -100]\n",
    "    hengxiang204060_nochong_df.to_csv(f\"../../Fulaoshi/230821_mzML_res/{analysis_path}/static_deduplicated_hengxiang204060_{sim_method}_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e5da164d-0322-4fd5-98ee-c8620c733c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ref_ev</th>\n",
       "      <th>ref_mz</th>\n",
       "      <th>ref_rt_left</th>\n",
       "      <th>ref_rt_right</th>\n",
       "      <th>Area</th>\n",
       "      <th>ms2_ev</th>\n",
       "      <th>ms2_index</th>\n",
       "      <th>ms2_mz</th>\n",
       "      <th>ms2_rt</th>\n",
       "      <th>ms1_intensity</th>\n",
       "      <th>Area13_2list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13579</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24216</td>\n",
       "      <td>45.18</td>\n",
       "      <td>83.34</td>\n",
       "      <td>104877925.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13589</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24216</td>\n",
       "      <td>45.54</td>\n",
       "      <td>80.40</td>\n",
       "      <td>104479167.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13569</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24219</td>\n",
       "      <td>46.26</td>\n",
       "      <td>81.24</td>\n",
       "      <td>107659395.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24222</td>\n",
       "      <td>44.88</td>\n",
       "      <td>83.64</td>\n",
       "      <td>104182764.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13539</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24222</td>\n",
       "      <td>46.02</td>\n",
       "      <td>83.28</td>\n",
       "      <td>106314221.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13598</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24222</td>\n",
       "      <td>46.26</td>\n",
       "      <td>83.52</td>\n",
       "      <td>105676604.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13487</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24225</td>\n",
       "      <td>45.24</td>\n",
       "      <td>81.36</td>\n",
       "      <td>106543262.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13608</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24225</td>\n",
       "      <td>46.20</td>\n",
       "      <td>83.04</td>\n",
       "      <td>106350927.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24228</td>\n",
       "      <td>40.20</td>\n",
       "      <td>82.32</td>\n",
       "      <td>109812085.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13529</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24228</td>\n",
       "      <td>45.12</td>\n",
       "      <td>83.22</td>\n",
       "      <td>106729430.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24234</td>\n",
       "      <td>46.14</td>\n",
       "      <td>82.02</td>\n",
       "      <td>105591845.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13549</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24240</td>\n",
       "      <td>45.90</td>\n",
       "      <td>81.36</td>\n",
       "      <td>105958394.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13559</th>\n",
       "      <td>35</td>\n",
       "      <td>297.24246</td>\n",
       "      <td>45.18</td>\n",
       "      <td>82.62</td>\n",
       "      <td>109268521.0</td>\n",
       "      <td>204060</td>\n",
       "      <td>836</td>\n",
       "      <td>297.242218</td>\n",
       "      <td>55.972308</td>\n",
       "      <td>21361174.0</td>\n",
       "      <td>[[59815727, 23964964, 12438672, 256215103, 102...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ref_ev     ref_mz  ref_rt_left  ref_rt_right         Area  ms2_ev  \\\n",
       "13579      35  297.24216        45.18         83.34  104877925.0  204060   \n",
       "13589      35  297.24216        45.54         80.40  104479167.0  204060   \n",
       "13569      35  297.24219        46.26         81.24  107659395.0  204060   \n",
       "13507      35  297.24222        44.88         83.64  104182764.0  204060   \n",
       "13539      35  297.24222        46.02         83.28  106314221.0  204060   \n",
       "13598      35  297.24222        46.26         83.52  105676604.0  204060   \n",
       "13487      35  297.24225        45.24         81.36  106543262.0  204060   \n",
       "13608      35  297.24225        46.20         83.04  106350927.0  204060   \n",
       "13519      35  297.24228        40.20         82.32  109812085.0  204060   \n",
       "13529      35  297.24228        45.12         83.22  106729430.0  204060   \n",
       "13497      35  297.24234        46.14         82.02  105591845.0  204060   \n",
       "13549      35  297.24240        45.90         81.36  105958394.0  204060   \n",
       "13559      35  297.24246        45.18         82.62  109268521.0  204060   \n",
       "\n",
       "       ms2_index      ms2_mz     ms2_rt  ms1_intensity  \\\n",
       "13579        836  297.242218  55.972308     21361174.0   \n",
       "13589        836  297.242218  55.972308     21361174.0   \n",
       "13569        836  297.242218  55.972308     21361174.0   \n",
       "13507        836  297.242218  55.972308     21361174.0   \n",
       "13539        836  297.242218  55.972308     21361174.0   \n",
       "13598        836  297.242218  55.972308     21361174.0   \n",
       "13487        836  297.242218  55.972308     21361174.0   \n",
       "13608        836  297.242218  55.972308     21361174.0   \n",
       "13519        836  297.242218  55.972308     21361174.0   \n",
       "13529        836  297.242218  55.972308     21361174.0   \n",
       "13497        836  297.242218  55.972308     21361174.0   \n",
       "13549        836  297.242218  55.972308     21361174.0   \n",
       "13559        836  297.242218  55.972308     21361174.0   \n",
       "\n",
       "                                            Area13_2list  \n",
       "13579  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13589  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13569  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13507  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13539  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13598  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13487  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13608  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13519  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13529  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13497  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13549  [[59815727, 23964964, 12438672, 256215103, 102...  \n",
       "13559  [[59815727, 23964964, 12438672, 256215103, 102...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zong_static1_df = zong_df.groupby(groupby_list).agg(b2_index=('b2_index', list_agg), b2_mz=('b2_mz', list_agg),  \n",
    "                                                    b2_rt_left=('b2_rt_left', 'min'),b2_rt_right=('b2_rt_right', 'max'),).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d1fff-5ff6-4b46-9e31-d6aed147cdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e061a0-4ad9-4ba7-b0b8-0bca9b4ddf88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
